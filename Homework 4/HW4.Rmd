---
title: 'Homework #4: Persado'
author: Eric Cheng, Julio Guzman, Vinh Luong, Jorge Ortega, Shao Zhu
output: pdf_document
fontsize: 12
geometry: margin=0.6in
---


# Load Packages

```{r}
library(xlsx)
library(AlgDesign)
```


# Load Data

```{r}
df <- read.xlsx("persado_experiment.xlsx", sheetIndex = 1)
```


# Q1: Assuming that each all relevant variables were tested how many possible message combinations are there?

```{r}
# Number of Levels per variable
intro <- 4
headline <- 4
main_text <- 2
button <- 2
action <- 2
purpose <- 4
symbol <- 2
```

The number of possible combinations is __`r intro * headline * main_text * button * action * purpose * symbol`__.


# Q2: Estimate two logit models based on the data (assuming a simple linear specification) - one for opens and another for clicks. Discuss your results based on the nature of the variables (see variable names and descriptions tab).

```{r}
df <- df[1:16, 4:14]
df$successful_sent = df$unique_sent - df$bounced
```

Logit model for Opens:

```{r}
opens_model <-
  glm(cbind(unique_opened, successful_sent - unique_opened) ~ 
        intro + headline + main_text + button + action + purpose + symbol,
      data = df,
      family = 'binomial')

summary(opens_model)
```

Some comments on this model:

- __Headline__: All options are not statistically different, suggesting the Headline does not reallyt matter to the probabilility of people opening the message;
- __Main Text__: The second choice _"Check out our selection for you - add a new phone, tablet, or other device!"_ has a negative significant coefficient. This is perhaps because it is less informative than the first choice in terms of articulating the benefits;
- __Action__: The second choice _"Click Here to..."_ is also negative and significant, suggesting a higher tendency for people to find that deceiving

```{r}
# Coefficients analysis
Beta1 <- coef(opens_model)
p.hat1 <- exp(Beta1["(Intercept)"])/(1+exp(Beta1["(Intercept)"]))
p.data1 <- df$unique_opened[1]/df$"successful_sent"[1]
Odds1 <- exp(Beta1); Odds1
```

Nonetheless the comments on the model made before, as appreciated in the result of the odds, all odds for the model are very close to 1, this means that the base probability of opening an email :__`r p.hat1`__ is almost not affected by the variations in the model.


This is in line with the no variability shown in the table below for the open rate:
```{r}
summary(df$'unique_open'/df$'successful_sent')
````


Logit model for Clicks:

```{r}
clicks_model <-
  glm(cbind(unique_clicks, successful_sent - unique_clicks) ~
        intro + headline + main_text + button + action + purpose + symbol,
      data = df,
      family = 'binomial')

summary(clicks_model)
```

There are some notable differences in this model vs. the one for Opens:

- __Headline__: all options are statistically significantly different now, suggesting people do care about what the Headline says in deciding whether to follow through. The first option _"You'll Love It"_ seems to be the worst, suggesting a degree of distrust for such a claim;
- __Action__: the second option _"Click Here to..."_ now has a positive significatn coefficient - so once people trust the content of the message, a prompt to click does lead to a higher tendency to click through.

```{r}
# Coefficients analysis
Beta2 <- coef(clicks_model)
p.hat2 <- exp(Beta2["(Intercept)"])/(1+exp(Beta2["(Intercept)"]))
p.data2 <- df$unique_clicks[1]/df$"successful_sent"[1]
Odds2 <- exp(Beta2); Odds2
```

In line with the comments made above, as appreciated in the result of the odds, some odds for certain variables of the model are very different from 1, this means that the base probability of clicking an email :__`r p.hat2`__ is affected by the variations. 

For example, introL3 increases the odds by __`r Odds2['introL3']`__. Other important variables are headlineL2, headlineL3, and actionL2.


# Q3: Use the estimated models to compute predicted probabilities for all possible message combinations (separate predictions for opens and clicks). Which messages have the highes fitted response probabilities? Are the two messages similar or different? Discuss.

```{r}
all_combinations <-
  gen.factorial(
    levels = c(4, 4, 2, 2, 2, 4, 2),
    factors = 'all',
    varNames = c('intro',
                 'headline',
                 'main_text',
                 'button',
                 'action',
                 'purpose',
                 'symbol'))

levels(all_combinations$intro) <- paste('L', 1:4, sep='')
levels(all_combinations$headline) <- paste('L', 1:4, sep='')
levels(all_combinations$main_text) <- paste('L', 1:2, sep='')
levels(all_combinations$button) <- paste('L', 1:2, sep='')
levels(all_combinations$action) <- paste('L', 1:2, sep='')
levels(all_combinations$purpose) <- paste('L', 1:4, sep='')
levels(all_combinations$symbol) <- paste('L', 1:2, sep='')
```

Open probabilities:

```{r}
open_probs <- predict(opens_model, newdata = all_combinations, type='response')

summary(open_probs)
```

The message with the highest predicted probability of being opened has the following configuration:

```{r}
all_combinations[which.max(open_probs), ]
```

Overall, however, the probability of a message being opened ranges extremely narrowly in the mid-50%s. We can practically say that a message has a 50-50 chance of being opened, no matter how it appears.

Click probabilities:

```{r}
click_probs <- predict(clicks_model, newdata = all_combinations, type='response')

summary(click_probs)
```

The click-through probabilities, unlike the open probabilities, have meaningful variation among them. The message with the highest predicted probability of being clicked through has the following configuration:

```{r}
all_combinations[which.max(click_probs), ]
```


# Q4: Please use the historical data provided in the project section of chalk to provide me your experimental design. See HistData.R for details.


